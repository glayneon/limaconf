images:
- location: "https://cloud-images.ubuntu.com/releases/noble/release-20250313/ubuntu-24.04-server-cloudimg-amd64.img"
  arch: "x86_64"
  digest: "sha256:eacac65efe9e9bae0cbcb3f9d5c2b5e8c5313fa78a3bc401c3fb28b2d48cefc0"
- location: "https://cloud-images.ubuntu.com/releases/noble/release-20250313/ubuntu-24.04-server-cloudimg-arm64.img"
  arch: "aarch64"
  digest: "sha256:103f31c5a5b7f031a60ce3555c8fbd56317fd8ffbaaa7e17002879e6157d546d"
- location: "https://cloud-images.ubuntu.com/releases/noble/release/ubuntu-24.04-server-cloudimg-amd64.img"
  arch: "x86_64"
- location: "https://cloud-images.ubuntu.com/releases/noble/release/ubuntu-24.04-server-cloudimg-arm64.img"
  arch: "aarch64"
# Mounts are disabled in this template, but can be enabled optionally.
mounts: []
containerd:
  system: true
  user: false
provision:
# See <https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/>
- mode: system
  script: |
    #!/bin/bash
    set -eux -o pipefail
    command -v kubeadm >/dev/null 2>&1 && exit 0
    # Install and configure prerequisites
    cat <<EOF | sudo tee /etc/modules-load.d/containerd.conf
    overlay
    br_netfilter
    EOF
    modprobe overlay
    modprobe br_netfilter
    # Add kernel subsystem changes to support many pods in running kubeflow
    cat <<EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
    net.bridge.bridge-nf-call-iptables  = 1
    net.ipv4.ip_forward                 = 1
    net.bridge.bridge-nf-call-ip6tables = 1
    fs.inotify.max_user_instances       = 2280
    fs.inotify.max_user_watches         = 1255360
    EOF
    sysctl --system
    # Installing kubeadm, kubelet and kubectl
    export DEBIAN_FRONTEND=noninteractive
    # Change the apt source to the local mirror
    sed -i 's|http://archive.ubuntu.com/ubuntu|https://mirror.techlabs.co.kr/ubuntu/|g' /etc/apt/sources.list.d/ubuntu.sources
    sed -i 's|http://security.ubuntu.com/ubuntu|https://mirror.techlabs.co.kr/ubuntu/|g' /etc/apt/sources.list.d/ubuntu.sources
    apt-get update
    apt-get install -y apt-transport-https ca-certificates curl open-iscsi
    VERSION=$(curl -L -s https://dl.k8s.io/release/stable.txt | sed -e 's/v//' | cut -d'.' -f1-2)
    echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v${VERSION}/deb/ /" | sudo tee /etc/apt/sources.list.d/kubernetes.list
    curl -fsSL https://pkgs.k8s.io/core:/stable:/v${VERSION}/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
    apt-get update
    # cri-tools
    apt-get install -y cri-tools
    cat  <<EOF | sudo tee /etc/crictl.yaml
    runtime-endpoint: unix:///run/containerd/containerd.sock
    EOF
    # cni-plugins
    apt-get install -y kubernetes-cni
    rm -f /etc/cni/net.d/*.conf*
    apt-get install -y kubelet kubeadm kubectl && apt-mark hold kubelet kubeadm kubectl
    systemctl enable --now kubelet
# See <https://kubernetes.io/docs/setup/production-environment/container-runtimes/>
- mode: system
  script: |
    #!/bin/bash
    set -eux -o pipefail
    grep SystemdCgroup /etc/containerd/config.toml && exit 0
    grep "version = 2" /etc/containerd/config.toml || exit 1
    # Configuring the systemd cgroup driver
    # Overriding the sandbox (pause) image
    cat <<EOF >>/etc/containerd/config.toml
      [plugins]
        [plugins."io.containerd.grpc.v1.cri"]
          sandbox_image = "$(kubeadm config images list | grep pause | sort -r | head -n1)"
          [plugins."io.containerd.grpc.v1.cri".containerd]
            [plugins."io.containerd.grpc.v1.cri".containerd.runtimes]
              [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
                runtime_type = "io.containerd.runc.v2"
                [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
                  SystemdCgroup = true
    EOF
    systemctl restart containerd
    systemctl restart containerd
# See <https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/>
- mode: system
  script: |
    #!/bin/bash
    set -eux -o pipefail
    test -e /etc/kubernetes/admin.conf && exit 0
    IPADDR=$(ip -4 a show eth0 | grep -oP '(?<=inet\s)\d+(\.\d+){3}')
    export KUBECONFIG=/etc/kubernetes/admin.conf
    systemctl stop kubelet
    kubeadm config images list
    kubeadm config images pull --cri-socket=unix:///run/containerd/containerd.sock
    systemctl start kubelet
    # Initializing your control-plane node
    # Change IP address properly for serving Kubernetes API server
    cat <<EOF >kubeadm-config.yaml
    kind: InitConfiguration
    apiVersion: kubeadm.k8s.io/v1beta4
    nodeRegistration:
      criSocket: unix:///run/containerd/containerd.sock
    ---
    kind: ClusterConfiguration
    apiVersion: kubeadm.k8s.io/v1beta4
    apiServer:
      certSANs:
      - "127.0.0.1"
      - "${IPADDR}"
      extraArgs:
      - name: "service-account-issuer"
        value: "https://kubernetes.default.svc"
      - name: "service-account-signing-key-file"
        value: "/etc/kubernetes/pki/sa.key"
      - name: "advertise-address"
        value: "${IPADDR}"
    networking:
      dnsDomain: cluster.local
      podSubnet: "10.244.0.0/16"
      serviceSubnet: 10.96.0.0/12
    ---
    kind: KubeletConfiguration
    apiVersion: kubelet.config.k8s.io/v1beta1
    cgroupDriver: systemd
    EOF
    # Skip kube-proxy
    kubeadm init --config kubeadm-config.yaml --skip-phases=addon/kube-proxy
    # kubeadm init --config kubeadm-config.yaml
    # Control plane node isolation
    kubectl taint nodes --all node-role.kubernetes.io/control-plane-
    # Installing a Pod network add-on, Calico
    # kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.29.3/manifests/calico.yaml
    # install MetalLB
    # kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.14.9/config/manifests/metallb-native.yaml
    # Replace the server address with localhost, so that it works also from the host
    sed -e "/server:/ s|https://.*:\([0-9]*\)$|https://127.0.0.1:\1|" -i $KUBECONFIG
    mkdir -p ${HOME:-/root}/.kube && cp -f $KUBECONFIG ${HOME:-/root}/.kube/config
- mode: system
  script: |
    #!/bin/bash
    set -eux -o pipefail
    export KUBECONFIG=/etc/kubernetes/admin.conf
    mkdir -p {{.Home}}/.kube
    cp -f $KUBECONFIG {{.Home}}/.kube/config
    chown -R {{.User}} {{.Home}}/.kube
    cat <<EOF >> {{.Home}}/.bashrc
    alias k="kubectl"
    EOF
- mode: system
  script: |
    #!/bin/bash
    set -eux -o pipefail
    # install k9s and kustomize
    curl -sSL -O https://github.com/derailed/k9s/releases/download/v0.40.10/k9s_linux_amd64.deb && sudo dpkg -i ./k9s*.deb
    curl -sSL -O https://github.com/kubernetes-sigs/kustomize/releases/download/kustomize%2Fv5.6.0/kustomize_v5.6.0_linux_amd64.tar.gz && tar xvfz ./kustomize_*_amd64.tar.gz && sudo mv ./kustomize /usr/local/bin/kustomize
    curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
    # install ovn-k8s
    export KUBECONFIG=/etc/kubernetes/admin.conf
    git clone https://github.com/ovn-org/ovn-kubernetes.git
    cd ovn-kubernetes/helm/ovn-kubernetes
    git checkout v1.0.0
    helm install ovn-kubernetes . -f values.yaml \
     --set k8sAPIServer="https://${IPADDR}:6443"
probes:
- description: "kubeadm to be installed"
  script: |
    #!/bin/bash
    set -eux -o pipefail
    if ! timeout 30s bash -c "until command -v kubeadm >/dev/null 2>&1; do sleep 3; done"; then
      echo >&2 "kubeadm is not installed yet"
      exit 1
    fi
  hint: |
    See "/var/log/cloud-init-output.log" in the guest
- description: "kubernetes images to be pulled"
  script: |
    #!/bin/bash
    set -eux -o pipefail
    if ! timeout 30s bash -c "images=\"$(kubeadm config images list)\"; until for image in \$images; do sudo crictl image -q \$image | grep -q sha256; done; do sleep 3; done"; then
      echo >&2 "k8s images are not pulled yet"
      exit 1
    fi
- description: "kubeadm to be completed"
  script: |
    #!/bin/bash
    set -eux -o pipefail
    if ! timeout 300s bash -c "until test -f /etc/kubernetes/admin.conf; do sleep 3; done"; then
      echo >&2 "k8s is not running yet"
      exit 1
    fi
  hint: |
    The k8s kubeconfig file has not yet been created.
- description: "kubernetes cluster to be running"
  script: |
    #!/bin/bash
    set -eux -o pipefail
    if ! timeout 300s bash -c "until kubectl version >/dev/null 2>&1; do sleep 3; done"; then
      echo >&2 "kubernetes cluster is not up and running yet"
      exit 1
    fi
- description: "OVN-k8s deployment to be running"
  script: |
    #!/bin/bash
    set -eux -o pipefail
    if ! timeout 300s bash -c "until kubectl wait -n ovn-kubernetes --timeout=3s --for=condition=available deploy ovnkube-db 2>&1; do sleep 3; done"; then
      echo >&2 "Failed to start ovnkube-db..."
      exit 1
    fi
copyToHost:
- guest: "/etc/kubernetes/admin.conf"
  host: "{{.Dir}}/copied-from-guest/kubeconfig.yaml"
  deleteOnStop: true
message: |
  To run `kubectl` on the host (assumes kubectl is installed), run the following commands:
  ------
  export KUBECONFIG="{{.Dir}}/copied-from-guest/kubeconfig.yaml"
  kubectl ...
  ------
# test-vm
cpus: 12
memory: 16GiB
disk: 100GiB
# kubeflow
# cpus: 10
# memory: 18GiB
# arch: x86_64
# disk: 100GiB
# networks:
#   - lima: shared